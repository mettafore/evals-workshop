{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c842dcf",
   "metadata": {},
   "source": [
    "# Explore Email Dataset\n",
    "\n",
    "This notebook trims the 517k-message Enron corpus into a workshop-ready pool of threads.\n",
    "We focus on three steps:\n",
    "- profile the raw email table and capture baseline metrics\n",
    "- parse headers into structured columns we can filter on\n",
    "- apply time, keyword, and thread-length filters to surface high-signal conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ad6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "from email.utils import parseaddr, getaddresses\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures.process import BrokenProcessPool\n",
    "from pprint import pprint\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 160)\n",
    "\n",
    "DATA_PATH = Path('../data/emails.csv')\n",
    "TIME_WINDOW = (pd.Timestamp('2001-03-01'), pd.Timestamp('2001-06-30'))\n",
    "THREAD_LEN_RANGE = (2, 8)\n",
    "ACTION_KEYWORDS = [\n",
    "    'deadline',\n",
    "    'deliver',\n",
    "    'deliverable',\n",
    "    'please review',\n",
    "    'fyi',\n",
    "    'action item',\n",
    "    'follow up',\n",
    "    'schedule',\n",
    "    'update',\n",
    "    'approve',\n",
    "]\n",
    "ACTION_PATTERN = re.compile('|'.join(re.escape(k) for k in ACTION_KEYWORDS), flags=re.IGNORECASE)\n",
    "plt.style.use('seaborn-v0_8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34efda",
   "metadata": {},
   "source": [
    "## Load raw email table\n",
    "\n",
    "`emails.csv` stores the raw MIME messages with a source filepath. We keep the full table in\n",
    "memory for now so downstream filters can operate on the entire quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfe2d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 517,401 rows – 2 columns (~1,403.6 MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>raw_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.evans@thyme&gt;\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.evans@thyme&gt;\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.evans@thyme&gt;\\nDate: Wed, 18 Oct 2000 03:00:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: leah.arsdall@enro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file  \\\n",
       "0    allen-p/_sent_mail/1.   \n",
       "1   allen-p/_sent_mail/10.   \n",
       "2  allen-p/_sent_mail/100.   \n",
       "\n",
       "                                                                                                                                                       raw_message  \n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron....  \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enro...  \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.evans@thyme>\\nDate: Wed, 18 Oct 2000 03:00:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: leah.arsdall@enro...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(DATA_PATH, usecols=['file', 'message']).rename(columns={'message': 'raw_message'})\n",
    "raw_shape = raw_df.shape\n",
    "raw_mem_mb = raw_df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "print(f'Loaded {raw_shape[0]:,} rows – {raw_shape[1]} columns (~{raw_mem_mb:,.1f} MB)')\n",
    "display(raw_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60eb8737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Message-ID: <2332992.1075859168847.JavaMail.evans@thyme>\\nDate: Mon, 10 Dec 2001 08:30:18 -0800 (PST)\\nFrom: ecn38c2.conf.@enron.com\\nTo: karen.gruesen@enron.com, jim.coffey@enron.com, lou.stoler@enron.com, \\n\\tstuart.zisman@enron.com, brian.redmond@enron.com, \\n\\tgerald.nemec@enron.com\\nSubject: Gerald Nemec would like to meet re Bridgeline\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Conf. Room ECN38C2 </O=ENRON/OU=NA/CN=RECIPIENTS/CN=MBX_CRECN38C2>\\nX-To: Gruesen, Karen </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Kgruese>, Coffey Jr., Jim </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Jcoffey>, Stoler, Lou </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lstolle>, Zisman, Stuart </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Szisman>, Redmond, Brian </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Bredmon>, Nemec, Gerald </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Gnemec>\\nX-cc: \\nX-bcc: \\nX-Folder: \\\\Gerald_Nemec_Jan2002\\\\Nemec, Gerald\\\\Inbox\\nX-Origin: Nemec-G\\nX-FileName: gnemec (Non-Privileged).pst\\n\\nWhen: Monday, December 10, 2001 1:30 PM-2:30 PM (GMT-06:00) Central Time (US & Canada).\\nWhere: ECN38C2\\n\\n*~*~*~*~*~*~*~*~*~*\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.sample(1)['raw_message'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b80da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Sample email: skilling-j/deleted_items/343.\n",
       "\n",
       "**Header preview**\n",
       "\n",
       "```\n",
       "Message-ID: <19499770.1075852655147.JavaMail.evans@thyme>\n",
       "Date: Sun, 17 Jun 2001 14:55:02 -0700 (PDT)\n",
       "From: 40enron@enron.com\n",
       "Subject: Credit Union Offers Flood Relief Loans\n",
       "Mime-Version: 1.0\n",
       "Content-Type: text/plain; charset=ANSI_X3.4-1968\n",
       "Content-Transfer-Encoding: 7bit\n",
       "X-From: Enron Federal Credit Union@ENRON <IMCEANOTES-Enron+20Federal+20Credit+20Union+40ENRON@ENRON.com>\n",
       "X-To: All Enron Downtown@ENRON\n",
       "X-cc:\n",
       "X-bcc:\n",
       "X-Folder: \\JSKILLIN (Non-Privileged)\\Deleted Items\n",
       "X-Origin: Skilling-J\n",
       "X-FileName: JSKILLIN (Non-Privileged).pst\n",
       "```\n",
       "\n",
       "**Body preview**\n",
       "\n",
       "```\n",
       "Credit Union Offers Flood Relief Loans\n",
       "Our thoughts and support go out to all Enron employees who have been affected by our recent flooding.  Enron Federal Credit Union would like to assist those employees who may be in need of financial assistance with a Signature Loan or Auto Loan.\n",
       "\n",
       "Two types of special Flood Relief Loans* are available including:\n",
       "\n",
       "?\tSignature Loans* for a 6 month term, single pay plan, at a 5.00% Fixed APR, and $10,000 maximum.\n",
       "\n",
       "?\tAuto Loans** are available at 6.49% Fixed APR on all conventional loan terms, with a 90-Day No Payment Option.\n",
       "\n",
       "Apply on-line, 24x7 at enronfcu.com, then select Anytime Loans and the loan type.  Please type Flood Relief in the Purpose of Loan Field.  Or, call Anytime Loans at 800.235.8763 and reference our Flood Relief Loan.  For more information, please e-mail efcu@enron.com or call our Lending Department at x30578.\n",
       "\n",
       "*Must be a Credit Union member to apply. Unpaid loans must pay interest due after 6 months, and renew on monthly payments at the regular lobby rate at time of renewal. **Term will be extended and finance charges will continue to accrue during the 90-day period. Subject to normal underwriting requirements. Auto Balloon Notes and current loans are excluded from this offer. No other discounts apply. EFCU is an Equal Housing Lender & NCUA Insured. Offers end July 15, 2001.\n",
       "\n",
       "\n",
       "Water Damaged Vehicle Inspection Service Available\n",
       "Due to the recent flooding in our area, many of you may now be in the market to buy a new or used vehicle. To help ensure you do not unknowingly purchase a new or used vehicle that has been flood damaged, please call our service partner, Auto Exam. Auto Exam will send a  technician to your location to perform a bumper-to-bumper inspection on the vehicle, and provide you with a detailed report on the condition of the vehicle. Complete inspections are available for $109.00. Call 713.944.2944 for an appointment today, or visit our web site at enronfcu.com and select Auto Center for more information.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render a sampled raw message as a layperson-friendly preview\n",
    "sample_row = raw_df.sample(1).iloc[0]\n",
    "raw_message = sample_row['raw_message']\n",
    "\n",
    "header_lines: list[str] = []\n",
    "body_lines: list[str] = []\n",
    "found_break = False\n",
    "for line in raw_message.splitlines():\n",
    "    if not found_break and line.strip() == '':\n",
    "        found_break = True\n",
    "        continue\n",
    "    if found_break:\n",
    "        body_lines.append(line.rstrip())\n",
    "    else:\n",
    "        header_lines.append(line.rstrip())\n",
    "\n",
    "header_preview = '\\n'.join(header_lines)\n",
    "body_preview = '\\n'.join(body_lines[:40]).strip()\n",
    "if len(body_lines) > 40:\n",
    "    body_preview += '\\n...'\n",
    "body_preview = body_preview or '[empty body]'\n",
    "\n",
    "email_title = sample_row['file']\n",
    "\n",
    "markdown = (\n",
    "    f\"### Sample email: {email_title}\\n\\n\"\n",
    "    \"**Header preview**\\n\\n\"\n",
    "    \"```\\n\"\n",
    "    f\"{header_preview}\\n\"\n",
    "    \"```\\n\\n\"\n",
    "    \"**Body preview**\\n\\n\"\n",
    "    \"```\\n\"\n",
    "    f\"{body_preview}\\n\"\n",
    "    \"```\"\n",
    ")\n",
    "\n",
    "display(Markdown(markdown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13998121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render properly meesage with pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a849b",
   "metadata": {},
   "source": [
    "## Extract structured headers\n",
    "\n",
    "We split the RFC-822 header block from the body, handle folded header lines, and derive a\n",
    "normalized subject for thread grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654e8436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HEADER_BREAK = re.compile(r'\r",
    "?\n",
    "\r",
    "?\n",
    "')\n",
    "SUBJECT_PREFIX_RE = re.compile(r'^(re|fw|fwd):\\s*', flags=re.IGNORECASE)\n",
    "MESSAGE_ID_RE = re.compile(r'<([^>]+)>')\n",
    "WHITESPACE_RE = re.compile(r'\\s+')\n",
    "\n",
    "\n",
    "def clean_message_id(value: str | None) -> str | None:\n",
    "    if not value:\n",
    "        return None\n",
    "    value = value.strip()\n",
    "    if value.startswith('<') and value.endswith('>'):\n",
    "        value = value[1:-1]\n",
    "    value = value.strip()\n",
    "    if not value:\n",
    "        return None\n",
    "    return value.lower()\n",
    "\n",
    "\n",
    "def extract_message_ids(raw: str | None) -> list[str]:\n",
    "    if not raw:\n",
    "        return []\n",
    "    matches = MESSAGE_ID_RE.findall(raw)\n",
    "    if not matches:\n",
    "        tokens = re.split(r'[\\s,]+', raw)\n",
    "        matches = [token for token in tokens if token]\n",
    "    cleaned: list[str] = []\n",
    "    for candidate in matches:\n",
    "        clean = clean_message_id(candidate)\n",
    "        if clean:\n",
    "            cleaned.append(clean)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def split_headers_body(raw: str) -> tuple[str, str]:\n",
    "    if not isinstance(raw, str):\n",
    "        return '', ''\n",
    "    parts = HEADER_BREAK.split(raw, maxsplit=1)\n",
    "    header_block = parts[0] if parts else ''\n",
    "    body = parts[1] if len(parts) > 1 else ''\n",
    "    return header_block, body\n",
    "\n",
    "\n",
    "def parse_header_block(block: str) -> dict[str, str]:\n",
    "    headers: dict[str, str] = {}\n",
    "    current_key: str | None = None\n",
    "    for line in block.splitlines():\n",
    "        if not line:\n",
    "            current_key = None\n",
    "            continue\n",
    "        if line.startswith((' ', '\t')) and current_key:\n",
    "            headers[current_key] += f' {line.strip()}'\n",
    "            continue\n",
    "        if ':' not in line:\n",
    "            current_key = None\n",
    "            continue\n",
    "        key, value = line.split(':', 1)\n",
    "        current_key = key.strip().lower()\n",
    "        headers[current_key] = value.strip()\n",
    "    return headers\n",
    "\n",
    "\n",
    "def normalize_subject(subject: str) -> str:\n",
    "    if not subject:\n",
    "        return ''\n",
    "    cleaned = subject\n",
    "    for _ in range(5):\n",
    "        updated = SUBJECT_PREFIX_RE.sub('', cleaned)\n",
    "        if updated == cleaned:\n",
    "            break\n",
    "        cleaned = updated\n",
    "    cleaned = WHITESPACE_RE.sub(' ', cleaned)\n",
    "    return cleaned.strip().lower()\n",
    "\n",
    "\n",
    "def parse_email_fields(raw: str) -> dict[str, object]:\n",
    "    header_block, body = split_headers_body(raw)\n",
    "    headers = parse_header_block(header_block)\n",
    "\n",
    "    subject = headers.get('subject', '').strip()\n",
    "    normalized_subject = normalize_subject(subject)\n",
    "\n",
    "    message_id = clean_message_id(headers.get('message-id'))\n",
    "    in_reply_to = clean_message_id(headers.get('in-reply-to'))\n",
    "    references = extract_message_ids(headers.get('references'))\n",
    "\n",
    "    date_raw = headers.get('date', '').strip() or None\n",
    "    from_raw = headers.get('from', '').strip() or None\n",
    "    from_email = parseaddr(from_raw)[1].lower() if from_raw else None\n",
    "\n",
    "    to_raw = headers.get('to', '').strip() or None\n",
    "    to_emails = [addr.lower() for _, addr in getaddresses([to_raw])] if to_raw else []\n",
    "    cc_raw = headers.get('cc', '').strip() or None\n",
    "    cc_emails = [addr.lower() for _, addr in getaddresses([cc_raw])] if cc_raw else []\n",
    "\n",
    "    participants = set()\n",
    "    if from_email:\n",
    "        participants.add(from_email)\n",
    "    participants.update(to_emails)\n",
    "    participants.update(cc_emails)\n",
    "    participants_key = ';'.join(sorted(participants)) if participants else None\n",
    "\n",
    "    keyword_text = f\"{subject}\n",
    "{body}\" if subject or body else ''\n",
    "    action_hit = bool(ACTION_PATTERN.search(keyword_text))\n",
    "\n",
    "    return {\n",
    "        'subject': subject or None,\n",
    "        'normalized_subject': normalized_subject or None,\n",
    "        'from_raw': from_raw,\n",
    "        'from_email': from_email,\n",
    "        'from_domain': from_email.split('@')[-1] if from_email and '@' in from_email else None,\n",
    "        'to_raw': to_raw,\n",
    "        'to_emails': ';'.join(to_emails) or None,\n",
    "        'cc_raw': cc_raw,\n",
    "        'cc_emails': ';'.join(cc_emails) or None,\n",
    "        'date_raw': date_raw,\n",
    "        'body': body.strip(),\n",
    "        'body_char_len': len(body),\n",
    "        'action_hit': action_hit,\n",
    "        'message_id': message_id,\n",
    "        'in_reply_to': in_reply_to,\n",
    "        'references': references or None,\n",
    "        'participants_key': participants_key,\n",
    "    }\n",
    "\n",
    "\n",
    "def assign_thread_ids(df: pd.DataFrame) -> pd.Series:\n",
    "    id_to_parent: dict[str, str | None] = {}\n",
    "    index_to_mid: dict[int, str | None] = {}\n",
    "    for row in df[['message_id', 'in_reply_to']].itertuples():\n",
    "        mid = row.message_id\n",
    "        parent = row.in_reply_to\n",
    "        if mid:\n",
    "            id_to_parent[mid] = parent if parent else None\n",
    "        index_to_mid[row.Index] = mid\n",
    "\n",
    "    root_cache: dict[str, str] = {}\n",
    "\n",
    "    def find_root(mid: str) -> str:\n",
    "        trail: list[str] = []\n",
    "        current = mid\n",
    "        while current:\n",
    "            if current in root_cache:\n",
    "                root = root_cache[current]\n",
    "                break\n",
    "            trail.append(current)\n",
    "            parent = id_to_parent.get(current)\n",
    "            if parent and parent in id_to_parent:\n",
    "                current = parent\n",
    "                continue\n",
    "            root = current\n",
    "            break\n",
    "        else:\n",
    "            root = mid\n",
    "        for node in trail:\n",
    "            root_cache[node] = root\n",
    "        return root\n",
    "\n",
    "    thread_ids: list[str] = []\n",
    "    for row in df.itertuples():\n",
    "        mid = index_to_mid[row.Index]\n",
    "        thread_id = None\n",
    "        if mid:\n",
    "            root_id = find_root(mid)\n",
    "            thread_id = f'mid::{root_id}'\n",
    "        if not thread_id:\n",
    "            sent_at_value = row.sent_at\n",
    "            week_bucket = 'unknown-week'\n",
    "            if pd.notna(sent_at_value):\n",
    "                sent_ts = pd.Timestamp(sent_at_value)\n",
    "                week_bucket = sent_ts.to_period('W').start_time.strftime('%Y-%m-%d')\n",
    "            parts = [part for part in ((row.normalized_subject or '').strip(), (row.participants_key or '').strip(), week_bucket) if part]\n",
    "            fallback = 'heuristic::' + '|'.join(parts)\n",
    "            if fallback == 'heuristic::':\n",
    "                fallback = f'row::{row.Index}'\n",
    "            thread_id = fallback\n",
    "        thread_ids.append(thread_id)\n",
    "    return pd.Series(thread_ids, index=df.index, name='thread_id')\n",
    "\n",
    "\n",
    "def parse_email_fields_parallel(messages: pd.Series, *, max_workers: int | None = None, chunksize: int = 2000) -> pd.DataFrame:\n",
    "    total = len(messages)\n",
    "    if total == 0:\n",
    "        return pd.DataFrame(index=messages.index)\n",
    "    cpu_count = os.cpu_count() or 1\n",
    "    if max_workers is None:\n",
    "        max_workers = max(1, min(cpu_count, 8)) if cpu_count else 1\n",
    "    message_list = messages.tolist()\n",
    "    try:\n",
    "        ctx = mp.get_context('fork')\n",
    "    except (AttributeError, ValueError):\n",
    "        ctx = mp.get_context()\n",
    "    try:\n",
    "        with ProcessPoolExecutor(max_workers=max_workers, mp_context=ctx) as executor:\n",
    "            parsed_iter = executor.map(parse_email_fields, message_list, chunksize=max(1, chunksize))\n",
    "            parsed_records = list(parsed_iter)\n",
    "    except BrokenProcessPool:\n",
    "        parsed_records = [parse_email_fields(raw) for raw in message_list]\n",
    "    return pd.DataFrame(parsed_records, index=messages.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68420033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_38002/1923134706.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_df['sent_at'] = pd.to_datetime(parsed_df['date_raw'], errors='coerce', utc=True).dt.tz_localize(None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sent_at</th>\n",
       "      <th>from_email</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>2000-10-18 10:00:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>2000-08-31 12:07:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allen-p/_sent_mail/1002.</td>\n",
       "      <td>2000-08-31 11:17:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allen-p/_sent_mail/1004.</td>\n",
       "      <td>2000-07-14 13:59:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: PRC review - phone calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allen-p/_sent_mail/101.</td>\n",
       "      <td>2000-10-17 09:26:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: High Speed Internet Access</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file             sent_at               from_email  \\\n",
       "2   allen-p/_sent_mail/100. 2000-10-18 10:00:00  phillip.allen@enron.com   \n",
       "4  allen-p/_sent_mail/1001. 2000-08-31 12:07:00  phillip.allen@enron.com   \n",
       "5  allen-p/_sent_mail/1002. 2000-08-31 11:17:00  phillip.allen@enron.com   \n",
       "7  allen-p/_sent_mail/1004. 2000-07-14 13:59:00  phillip.allen@enron.com   \n",
       "8   allen-p/_sent_mail/101. 2000-10-17 09:26:00  phillip.allen@enron.com   \n",
       "\n",
       "                          subject  \n",
       "2                        Re: test  \n",
       "4                       Re: Hello  \n",
       "5                       Re: Hello  \n",
       "7    Re: PRC review - phone calls  \n",
       "8  Re: High Speed Internet Access  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed rows: 484,164 (unique threads: 126,481)\n"
     ]
    }
   ],
   "source": [
    "parsed_records = parse_email_fields_parallel(raw_df['raw_message'])\n",
    "parsed_df = pd.concat([raw_df.drop(columns=['raw_message']), parsed_records], axis=1)\n",
    "parsed_df['sent_at'] = pd.to_datetime(parsed_df['date_raw'], errors='coerce', utc=True).dt.tz_localize(None)\n",
    "parsed_df = parsed_df.dropna(subset=['sent_at', 'normalized_subject'])\n",
    "parsed_df = parsed_df[parsed_df['normalized_subject'].str.len() > 0]\n",
    "parsed_df = parsed_df.drop_duplicates(subset=['file', 'sent_at', 'from_email', 'subject', 'body'])\n",
    "parsed_df['thread_id'] = assign_thread_ids(parsed_df)\n",
    "\n",
    "display(parsed_df[['file', 'sent_at', 'from_email', 'subject']].head(5))\n",
    "print(f'Parsed rows: {len(parsed_df):,} (unique threads: {parsed_df[\"normalized_subject\"].nunique():,})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da541f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file                                allen-p/_sent_mail/100.\n",
       "subject                                            Re: test\n",
       "normalized_subject                                     test\n",
       "from_raw                            phillip.allen@enron.com\n",
       "from_email                          phillip.allen@enron.com\n",
       "from_domain                                       enron.com\n",
       "to_raw                               leah.arsdall@enron.com\n",
       "date_raw              Wed, 18 Oct 2000 03:00:00 -0700 (PDT)\n",
       "body                         test successful.  way to go!!!\n",
       "body_char_len                                            30\n",
       "action_hit                                            False\n",
       "sent_at                                 2000-10-18 10:00:00\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cda5e0",
   "metadata": {},
   "source": [
    "## Apply message-level filters\n",
    "\n",
    "We focus on a high-signal quarter and emails that contain action cues or concrete\n",
    "commitments in the subject/body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af11424a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>emails</th>\n",
       "      <th>threads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parsed</td>\n",
       "      <td>484164</td>\n",
       "      <td>126481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time window 2001-03-01→2001-06-30</td>\n",
       "      <td>113187</td>\n",
       "      <td>27600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-empty body</td>\n",
       "      <td>113187</td>\n",
       "      <td>27600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keyword match</td>\n",
       "      <td>40200</td>\n",
       "      <td>9991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               stage  emails  threads\n",
       "0                             parsed  484164   126481\n",
       "1  time window 2001-03-01→2001-06-30  113187    27600\n",
       "2                     non-empty body  113187    27600\n",
       "3                      keyword match   40200     9991"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def snapshot(df: pd.DataFrame, stage: str) -> dict[str, object]:\n",
    "    return {\n",
    "        'stage': stage,\n",
    "        'emails': len(df),\n",
    "        'threads': df['thread_id'].nunique(),\n",
    "    }\n",
    "\n",
    "filtered_df = parsed_df.copy()\n",
    "progress = [snapshot(filtered_df, 'parsed')]\n",
    "\n",
    "if TIME_WINDOW:\n",
    "    start, end = TIME_WINDOW\n",
    "    time_mask = filtered_df['sent_at'].between(start, end)\n",
    "    filtered_df = filtered_df[time_mask]\n",
    "    progress.append(snapshot(filtered_df, f'time window {start.date()}→{end.date()}'))\n",
    "\n",
    "filtered_df = filtered_df[filtered_df['body_char_len'] > 0]\n",
    "progress.append(snapshot(filtered_df, 'non-empty body'))\n",
    "\n",
    "filtered_df = filtered_df[filtered_df['action_hit']]\n",
    "progress.append(snapshot(filtered_df, 'keyword match'))\n",
    "\n",
    "progress_df = pd.DataFrame(progress)\n",
    "display(progress_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c5140",
   "metadata": {},
   "source": [
    "## Evaluate thread structure\n",
    "\n",
    "Group by the metadata-derived `thread_id` (Message-ID chains with a subject/participant fallback), then keep those with 2–8 messages and at least two distinct senders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82995cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m thread_stats = (\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mfiltered_df\u001b[49m.groupby(\u001b[33m'\u001b[39m\u001b[33mnormalized_subject\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m     .agg(\n\u001b[32m      4\u001b[39m         message_count=(\u001b[33m'\u001b[39m\u001b[33mnormalized_subject\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      5\u001b[39m         first_sent=(\u001b[33m'\u001b[39m\u001b[33msent_at\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      6\u001b[39m         last_sent=(\u001b[33m'\u001b[39m\u001b[33msent_at\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      7\u001b[39m         keyword_hits=(\u001b[33m'\u001b[39m\u001b[33maction_hit\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      8\u001b[39m         unique_senders=(\u001b[33m'\u001b[39m\u001b[33mfrom_email\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m s: s.dropna().nunique()),\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m     .reset_index()\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m valid_threads = thread_stats[\n\u001b[32m     14\u001b[39m     (thread_stats[\u001b[33m'\u001b[39m\u001b[33mmessage_count\u001b[39m\u001b[33m'\u001b[39m].between(*THREAD_LEN_RANGE))\n\u001b[32m     15\u001b[39m     & (thread_stats[\u001b[33m'\u001b[39m\u001b[33mkeyword_hits\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m0\u001b[39m)\n\u001b[32m     16\u001b[39m     & (thread_stats[\u001b[33m'\u001b[39m\u001b[33munique_senders\u001b[39m\u001b[33m'\u001b[39m] >= \u001b[32m2\u001b[39m)\n\u001b[32m     17\u001b[39m ]\n\u001b[32m     19\u001b[39m candidate_df = filtered_df[filtered_df[\u001b[33m'\u001b[39m\u001b[33mnormalized_subject\u001b[39m\u001b[33m'\u001b[39m].isin(valid_threads[\u001b[33m'\u001b[39m\u001b[33mnormalized_subject\u001b[39m\u001b[33m'\u001b[39m])]\n",
      "\u001b[31mNameError\u001b[39m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": [
    "thread_stats = (\n",
    "    filtered_df.groupby('thread_id')\n",
    "    .agg(\n",
    "        subject=('subject', 'first'),\n",
    "        normalized_subject=('normalized_subject', 'first'),\n",
    "        message_count=('thread_id', 'size'),\n",
    "        first_sent=('sent_at', 'min'),\n",
    "        last_sent=('sent_at', 'max'),\n",
    "        keyword_hits=('action_hit', 'sum'),\n",
    "        unique_senders=('from_email', lambda s: s.dropna().nunique()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "valid_threads = thread_stats[\n",
    "    (thread_stats['message_count'].between(*THREAD_LEN_RANGE))\n",
    "    & (thread_stats['keyword_hits'] > 0)\n",
    "    & (thread_stats['unique_senders'] >= 2)\n",
    "]\n",
    "\n",
    "candidate_df = filtered_df[filtered_df['thread_id'].isin(valid_threads['thread_id'])]\n",
    "progress.append(snapshot(candidate_df, 'thread filters applied'))\n",
    "progress_df = pd.DataFrame(progress)\n",
    "\n",
    "preview_cols = ['thread_id', 'subject', 'message_count', 'unique_senders', 'first_sent', 'last_sent']\n",
    "display(valid_threads[preview_cols].sort_values('message_count', ascending=False).head(10))\n",
    "display(progress_df)\n",
    "print(f'Candidate threads: {len(valid_threads):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed620bda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_threads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvalid_threads\u001b[49m.empty:\n\u001b[32m      2\u001b[39m     counts = valid_threads[\u001b[33m'\u001b[39m\u001b[33mmessage_count\u001b[39m\u001b[33m'\u001b[39m].value_counts().sort_index()\n\u001b[32m      3\u001b[39m     ax = counts.plot(kind=\u001b[33m'\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33m#1f77b4\u001b[39m\u001b[33m'\u001b[39m, figsize=(\u001b[32m6\u001b[39m, \u001b[32m3\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'valid_threads' is not defined"
     ]
    }
   ],
   "source": [
    "if not valid_threads.empty:\n",
    "    counts = valid_threads['message_count'].value_counts().sort_index()\n",
    "    ax = counts.plot(kind='bar', color='#1f77b4', figsize=(6, 3))\n",
    "    ax.set_title('Thread length distribution (filtered)')\n",
    "    ax.set_xlabel('Messages per thread')\n",
    "    ax.set_ylabel('Thread count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No threads matched the current filter settings.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d182f",
   "metadata": {},
   "source": [
    "## Preview sample threads\n",
    "\n",
    "Spot-checking a few threads helps ensure the filters captured decisions and commitments\n",
    "that will make the manual labeling exercise engaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b62bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 13) (3840932027.py, line 13)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpreview = '\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 13)\n"
     ]
    }
   ],
   "source": [
    "def render_thread(thread_id: str, df: pd.DataFrame, body_lines: int = 10) -> None:\n",
    "    thread = df[df['thread_id'] == thread_id].sort_values('sent_at')\n",
    "    if thread.empty:\n",
    "        return\n",
    "    subject = thread['subject'].iloc[0] or '(no subject)'\n",
    "    normalized_subject = thread['normalized_subject'].iloc[0] or '(no normalized subject)'\n",
    "    md_lines: list[str] = [\n",
    "        f\"### {subject}\",\n",
    "        f\"- Thread ID: `{thread_id}`\",\n",
    "        f\"- Normalized subject: `{normalized_subject}`\",\n",
    "        f\"- Messages: {len(thread)}\",\n",
    "        f\"- Date span: {thread['sent_at'].min():%Y-%m-%d} → {thread['sent_at'].max():%Y-%m-%d}\",\n",
    "    ]\n",
    "    for row in thread.itertuples():\n",
    "        preview = '\n",
    "'.join(row.body.splitlines()[:body_lines]).strip()\n",
    "        if not preview:\n",
    "            preview = '*no body text*'\n",
    "        elif len(row.body.splitlines()) > body_lines:\n",
    "            preview += '\n",
    "...'\n",
    "        sender = row.from_raw or row.from_email or 'unknown sender'\n",
    "        md_lines.append(f\"**{sender}** — {row.sent_at:%Y-%m-%d %H:%M}\n",
    "\n",
    "{preview}\")\n",
    "    display(Markdown('\n",
    "\n",
    "'.join(md_lines)))\n",
    "\n",
    "if not valid_threads.empty:\n",
    "    sample_threads = (\n",
    "        valid_threads\n",
    "        .sort_values(['message_count', 'keyword_hits'], ascending=[False, False])\n",
    "        .head(3)['thread_id']\n",
    "    )\n",
    "    for thread_id in sample_threads:\n",
    "        render_thread(thread_id, candidate_df)\n",
    "else:\n",
    "    print('No threads available to preview.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0206ba",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Export `candidate_df` once you are happy with the filters (e.g., `candidate_df.to_json('data/threads_raw.jsonl', orient='records', lines=True)`).\n",
    "- Conduct manual review to curate ~40 golden threads, balancing your failure taxonomy.\n",
    "- Move parsing helpers into `workshop_utils.py` when finalizing the data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91b651",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "072bb3f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
